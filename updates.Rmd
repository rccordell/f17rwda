---
title: "Updates and In-Class Assignments"
output: 
  html_document:
    toc: true
    toc_depth: 2
    toc_float: true
    theme: journal
---

-----

# In-class Exercise: 10-16

Last year, as voters in the UK were debating whether to vote to leave the European Union, the following post appeared on the Facebook page of Tom Bradbury:

![Facebook post about Woman in Wales](http://ichef.bbci.co.uk/news/976/cpsprodpb/138FC/production/_90042108_tombradbury.jpg)

The post quickly began to go viral, and was (as of 15 October 2017) eventually shared 25,000 times, and reported around the media, from the *Times* of London to [the BBC](http://www.bbc.co.uk/newsbeat/article/36580448/welsh-woman-on-bus-shuts-down-racist-who-told-muslim-passenger-to-speak-english). I don't remember whether I first saw it on Twitter or Facebook, but certainly many, many people in my social media spheres shared, commented on, or chuckled over this story of a racist getting his comeuppance. The story was indeed *the most perfect thing*, particularly for people convinced that the Brexit vote was largely a reflection of racism or xenophobia.

The only problem? There was absolutely no evidence this story happened, and [pretty good evidence suggesting it likely didn't](https://www.newstatesman.com/politics/uk/2016/06/what-story-niqab-wearing-welsh-speaker-tells-us-about-what-we-want-hear). Soon after the story suffused the internet, (some) people began to realize it was remarkably similar to another vignette that had circulated through social media in 2014 or so, featuring an American man and a Navajo woman.

![post about woman speaking Navajo](https://i.imgur.com/zSYQjWy.jpg). 

However, these cautions about Bradbury's story circulated far less extensively than the original post. Later in 2016, the *New York Times* found something similar about [a fake story that had circulated about paid protesters bused to a Trump event](https://www.nytimes.com/2016/11/20/business/media/how-fake-news-spreads.html?_r=0). The original poster realized the error of his claims and tried to retract them, but his retractions circulated far less extensively than his original inflammatory post. 

As our readings showed, "fake news" isn't a phenomenon new to the 21st century, but the operations of online platforms may exacerbate problems inherent to human discernment. What qualities do stories like these share with the memes and gifs we discussed last week? Why are we so susceptible to stories like these, and how do our own biases relate to the media through which we find information? And of course there's the big question: what can be done about fake news?

-----

# In-class Exercise: 10-04 and 10-05

## Designing a Bot

Today you're going to work in pairs to design a bot. It could be a Twitter bot, or it could be another kind of automated producer of content. 

You won't be coding the bot (though you could try after this if you have the interest and ability) but you will be planning its operations quite formally. This does mean you can be ambitious: you only need to explain the process your bot would need to follow to create your intended output, but you do not need to understand precisely how to implement those steps in reality.

### What Kind of Bot?

You can design a bot of any kind, really, including:

1. A bot that creates literature, either by mashing up existing sources or by procedurally generating new material;
2. An activist bot that seeks to intervene in social or political conversations;
3. A non sequitur, mashup, or joke bot (this might overlap with #1) that makes the internet a slightly weirder place

Let's avoid Mad Libs bots for this exercise, in part because they don't require as much planning and in part because we already discussed one of these in detail. If you have an incredibly compelling idea for a Mad Libs-style bot I'm willing to listen, but don't invest too much time in it until I've approved of your plan.

### The Ingredients

In order to plan a bot, you will need:

1. Source data. This is a broad category, and can include:

  1. data drawn automatically from other websites, perhaps through an API (application programming interface). Think here about twitter bots that mashup other people's twitter posts.
  2. metadata drawn from other websites. Metadata is data about data, such as information on authors, dates, revision history, and so forth. Think about the bot that traces edits made to Wikipedia from Congress. It is using Wikipedia's metadata about the IP addresses of its editors' computers to identify the edits pertinent to the bot.
  3. material you create and/or maintain, perhaps stored in text files or spreadsheets. Think about the procedurally generated poems we read. Most of these are drawing not from the wild, wild web but instead from smaller datasets created expressly for the purpose of generating those poems.
  4. There are probably other possibilities.

2. An understanding of how your source data is structured. It won't be enough to say "We'll combine X with Y." How precisely will you combine those sources? Do they use similar syntactic structures that will make breaking them apart and re-joining them simple? From your data sources, what will you want to retain and what might you need to pass over or discard? That is, you likely can't use every bit of your sources, so what can you use and what can you not? What are the pieces of your data and precisely how will they be split, reworked, recombined, etc.? 
3. A clear sense of what your final product should look like. This may well be a *structural* understanding. The specific products of your bot may have qualities of randomness, but you should understand the general structure of those products. 

### What You Will Submit

A wireframe demonstrating how your bot will operate. You can draw this on paper or produce it on a computer, but it should visually show your bot's inputs, transformations, and outputs. It should be relatively detailed in describing all three so that I can fully understand what you want your bot to do and how.



-----

# In-class Exercise: 09-28

## Deciphering a Program

Below you'll find a snippet of some code that we work with in my [Technologies of Text](http://s17tot.ryancordell.org/) class. Today I just want to look at the code together and work to decipher it. You'll be in groups and I want you to try and answer, to the best of your ability:

1. From what point does the code begin? In other words, what's its source data?
2. What does this code *do*? When it's run, what is the final product?
3. How does the code get from its source data to that final product? Which of the intervening steps can you separate out and understand?
4. This last step is more abstract, but how are the operations of this code *similar* to writing, and how are they *distinct*?

# Mystery Code

```{r, eval = FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=50)}
my_wordnik_key <- "YOUR_API_KEY_GOES_HERE"

#the line below will set the "default" part of speech for your calls to Wordnik, but you will be able to override this setting in later code.
wordnik_pos = "adjective"

#
random_word <- function(key=my_wordnik_key,
                        pos=wordnik_pos, min_count=100, n=1,
                        min_length = 5, max_length = 10){
  
  param <- paste0("words.json/randomWords?hasDictionaryDef=true",
                  "&minCorpusCount=",min_count,
                  "&minLength=",min_length,
                  "&maxLength=",max_length,
                  "&limit=",n,
                  "&includePartOfSpeech=",pos)

  raw = birdnik:::query(key = key,params = param)
  do.call(rbind,lapply(raw,as.data.frame))
  
}

random_word(pos="verb",n=5, min_count=1000)
random_word(pos="interjection",n=10, min_count=100)

poem_word <- function(x) {
  random_word(pos=x,n=1,min_count=1000)[,2] %>%
    as.character()
}

poem_word("interjection")

poem <- paste(c(poem_word("verb"), " thy ", poem_word("noun"), " from ", poem_word("preposition")," my ", poem_word("noun"), ", and ", poem_word("verb"), " thy ", poem_word("noun"), " from ", poem_word("preposition"), " my ", poem_word("noun"), "! \nQuoth the Ravbot, '", poem_word("interjection"), "!'"), collapse = "")

cat(poem)

setup_twitter_oauth("YOUR_CONSUMER_KEY_GOES_HERE", 
                    "YOUR_CONSUMER_SECRET_GOES_HERE", 
                    'YOUR_ACCESS_TOKEN_GOES_HERE', 
                    'YOUR_ACCESS_SECRET_GOES_HERE')

woeid <- "2367105"

trend <- getTrends(woeid)[,1] %>%
  as_data_frame() %>%
  rename(trend = value) %>%
  filter(grepl("^#", trend))

poem <- paste(c(poem_word("verb"), " thy ", poem_word("noun"), " from ", poem_word("preposition")," my ", poem_word("noun"), ", and ", poem_word("verb"), " thy ", poem_word("noun"), " from ", poem_word("preposition"), " my ", poem_word("noun"), '!" \nQuoth the Ravbot, "Never ', trend %>% sample_n(1), "!'"), collapse = "")

cat(poem)

if(nchar(poem) < 140) {
  tweet(poem)
  } else {
    print("The poem is too long. Please rerun the generator and try again!")
  }
```

-----

# In-class Writing Prompt: 09-27
## ["The Truth of Fact, the Truth of Feeling"](https://subterraneanpress.com/magazine/fall_2013/the_truth_of_fact_the_truth_of_feeling_by_ted_chiang) by Ted Chiang

What is a memory? Increasingly, scientists are learning that memories are physically encoded in the brain. Scientists have even found ways to [suppress the formation of memories or selectively erase them](http://www.radiolab.org/story/91570-eternal-sunshine-of-the-spotless-rat/). Some of the best evidence, in fact, suggests that memories are reformed in the brain each time they are recalled, and that in fact the more often we recall something, [the less accurate that memory becomes](https://news.northwestern.edu/stories/2012/09/your-memory-is-like-the-telephone-game). Each time we remember something, we remember not the original event but instead our previous recollection of it, including all of the new ideas, connections, emotions, and other new contexts we've since associated with that memory. If you recall a moment with a dear childhood friend with whom you've since had a falling out, that memory will be tinged with anger, or sadness, or regret, and that tinge will echo through all future recollections of that moment, subtly reshaping it over time. 

Given all that, would you sign up for Remem if it were available? Why or why not?

-----

# In-class Writing Prompt: 09-18

Choose one of the following quotes about *17776*, one more about the form of the story and the other is more about its content. Either way, use your chosen quote to reflect on the story. You can take any path you'd like, but use specific examples if at all possible. 

1. The first comes from [an online Q&A with the author of *17776*, SBNation (Sports Blog Nation) creative director Jon Bois](https://www.sbnation.com/2017/7/24/16003968/17776-questions-and-answers). When "@Crazyeyesdave" asked, "Do you think weird experimental stories like this have a future in sports writing or was this a singular event?" Bois responded:
    
    > I hope so. Maybe not distant-future sports sci-fi, but that’s only one of a thousand lanes. I could go really, really long on this answer. I’ll keep it short: There are countless different ways to write, and things and ideas to write about. And the Internet offers a kaleidoscope of different formats, media, tools, sights, and sounds to tell your stories. And most of us are not even trying to scrape the surface of any of it. We’ve got to start thinking of the Internet as something more than a glow-in-the-dark newspaper.

2. In a post about *17776* at the A.V. club, [William Hughes takes a more philosophical bent](https://news.avclub.com/the-future-of-football-is-post-human-despair-and-fasci-1798263717), arguing that: 
    
    > "Bois’ serial story...seems largely concerned with the “why” of sports. That is, given the massive resources, time, and information at our disposal (not to mention those available to our descendants), why does communal game-playing still hold such an important place in society?"